<?xml version="1.0"?>
<rss version="2.0"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:dcterms="http://purl.org/dc/terms/" >
<channel>
<title>pages tagged Bitcoin</title>
<link>http://zander.github.io//tags/Bitcoin/</link>

<description>Toms place</description>
<generator>ikiwiki</generator>
<pubDate>Mon, 11 Jul 2016 13:22:59 +0000</pubDate>
<item>
	<title>Scaling Bitcoin</title>

	<guid isPermaLink="false">http://zander.github.io//posts/Scaling%20Bitcoin/</guid>

	<link>http://zander.github.io//posts/Scaling%20Bitcoin/</link>



	<category>Bitcoin</category>

	<category>Mining</category>


	<pubDate>Mon, 11 Jul 2016 11:22:31 +0000</pubDate>
	<dcterms:modified>2016-07-11T13:22:59Z</dcterms:modified>


	<description>&lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;

&lt;p&gt;One of the most talked about topics in 2016 when it comes to Bitcoin is the
lack of good plan for growing and scaling of the system into the future.&lt;/p&gt;

&lt;p&gt;I found this curious as anyone that starts to depend on any system should
do at least some investigation on what kind of growth it can handle, and
if it can actually do what we want it to do, this year and 5 years or
longer into the future.&lt;/p&gt;

&lt;p&gt;In this post I want to investigate what kind of scaling we can expect
Bitcoin to have and what we need to do to get more scaling out of the
system if it would not be enough.&lt;/p&gt;

&lt;h2 id=&quot;goals&quot;&gt;Goals&lt;/h2&gt;

&lt;p&gt;The number one reason that Bitcoin has value right now is its &lt;em&gt;promise&lt;/em&gt;
that Bitcoin will be used and seen as useful by millions of people in the
not-so-far future.  Any money only has value when enough people think it
has value.  Any money only has value when it actually can be &lt;em&gt;used&lt;/em&gt;. If
nobody accepts it for payments, the value will not be realized either.&lt;/p&gt;

&lt;p&gt;So the number one goal is to allow millions of people to be able to use
Bitcoin in their day-to-day lives. Where &#39;use&#39; is defined as making at
least one transaction a day. As any technology, we don&#39;t expect this load
to be available tomorrow, or this year because growth happens over time and
systems get build over time.&lt;/p&gt;

&lt;p&gt;So lets have a goal of 50 million users sending one transaction a day using
the Bitcoin network. Not today but 5 year in the future.&lt;/p&gt;

&lt;p&gt;Further goal is that for home-users the rate at which they can process
Bitcoin blocks should be at least twice the speed at which they get
created.  This means that if a system has no internet for an hour it would
take no more than half an hour at full speed to catch up.  Faster is
better, but slower than twice the creation speed is too slow.&lt;/p&gt;

&lt;h2 id=&quot;baseline&quot;&gt;Baseline&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;or, what is the current theoretical level of support&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Bitcoin, in the form of various node-software implementations, has had
several years to mature. The leadership was not really focused on growth
very much of this basic layer as we can see from the amount of progress
that started happening &lt;em&gt;after&lt;/em&gt; Bitcoin Classic and Bitcoin Unlimited
started competing. As usual, competition is good for the end-user and we
see some promise of future gains appear.&lt;/p&gt;

&lt;p&gt;But lets take a look at what kind of transaction load we could support
today.&lt;/p&gt;

&lt;p&gt;Last week &lt;a href=&quot;http://forum.bitcoin.com&quot;&gt;forum.bitcoin.com&lt;/a&gt; published a
&lt;a href=&quot;https://www.youtube.com/watch?time_continue=45&amp;amp;v=vL8ZRYsLdoY&quot;&gt;video&lt;/a&gt; about
time it takes to download, fully validate and check 7 years, or 420000
blocks of Bitcoin history. From day on of Bitcoin. This is 75GB of data
which took 6 hours and 50 minutes to fully validate on moderate hardware.
It wasn&#39;t cheap hardware, but it was certainly not top-of-the-line or
server hardware.  In other words, it is a good baseline.&lt;/p&gt;

&lt;p&gt;Taking a closer look at what was done in 6hours 50min&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;since block
&lt;a href=&quot;https://github.com/bitcoinclassic/bitcoinclassic/blob/1.1/src/chainparams.cpp#L154&quot;&gt;295000&lt;/a&gt;
till block 420000 (125000 blocks) each and every transaction signature has
been validated.&lt;/li&gt;
&lt;li&gt;75GB was downloaded from Bitcoin peers around the world.&lt;/li&gt;
&lt;li&gt;It build a UTXO database of 11 million transactions with 40 million
not yet spent Bitcoin addresses.  (see the RPC call gettxoutsetinfo).&lt;/li&gt;
&lt;li&gt;The 125000 blocks contained 104847758 &lt;a href=&quot;http://zander.github.io//tags/Bitcoin/findTxCount.pl&quot;&gt;transactions&lt;/a&gt; which
have all been validated.  Thats 105 Million txs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We understand that this was all done with no tweaks to the settings. This
was a Classic 1.1.0 node (equivalent to Bitcoin Core 0.12.1)&lt;/p&gt;

&lt;h2 id=&quot;whatneedswork&quot;&gt;What needs work?&lt;/h2&gt;

&lt;p&gt;Lets take a look and compare our baseline to our goal. Most people would
like software to always get faster and better, but priorities matter and we
should look at which parts need attention first.&lt;/p&gt;

&lt;p&gt;Our goal was that individual node needs to process in 24 hours about 50
million transactions.&lt;/p&gt;

&lt;p&gt;We noticed that in the baseline check of 6h50 hours it actually
downloaded and stored and checked almost 105 million transactions.
Which leads to a daily rate of 368 million transactions being downloaded and
validated.&lt;/p&gt;

&lt;p&gt;$$ TX_{day} = {{104847758 tx \over { 6 * 60 + 50 minutes}} * 24 * 60 minutes} = 368 million$$&lt;/p&gt;

&lt;p&gt;This means that our 5-years-in-the-future goal of 50 million transactions
per day is already today not an issue for bandwidth and for CPU power. In
fact, out baseline system managed to go over it with over a factor of 7.&lt;/p&gt;

&lt;p&gt;Today our baseline system could handle 7 times the volume that is the goal
5 years in the future!&lt;/p&gt;

&lt;p&gt;Today, an individual Bitcoin node can download, store and validate 368 million
transactions a day. Thats many times the volume that has &lt;em&gt;ever&lt;/em&gt; been sent
using Bitcoin.&lt;/p&gt;

&lt;h2 id=&quot;howdoiseethesystemscale&quot;&gt;How do I see the system scale?&lt;/h2&gt;

&lt;h3 id=&quot;atypicalhome-node&quot;&gt;A typical home-node&lt;/h3&gt;

&lt;p&gt;A node that validates all blocks fully is needed in order to keep
everyone honest. It also gives me peace of mind in that if I trust my node,
I don&#39;t have to trust anyone else.  So I foresee that you will get small
communities to gather around full nodes.  You can let your family use it,
or maybe your football club or church will set one up just to support the
community.  Individuals will then make their phone-wallets have at least
one host they trust, which is the one from your community.&lt;/p&gt;

&lt;p&gt;This preserves Bitcoins greatest assets, you don&#39;t have to trust banks or
governments. People trusting their local church or football club is much
more normal and common to do.&lt;/p&gt;

&lt;p&gt;Such a node would have no need to keep the full history till block zero. It
would turn on pruning.  With todays price of hardware this does not mean it
would stop being able to serve historic blocks because it could easily hold
a month of blocks history. This does, however, mean we need to make the
software a bit smarter. See some &lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../scaling/Pruning/&quot;&gt;pruning&lt;/a&gt; ideas.&lt;/p&gt;

&lt;p&gt;Harddrive space is cheap today. A 3TB harddrive stores 75 years of Bitcoin
history at current block size.  But what if we start getting to our goal.
What kind of harddrive do we need?&lt;/p&gt;

&lt;p&gt;The answer to that is that we don&#39;t need anything large at all. The idea
that we need to have a larger harddrive because blocks are bigger is a
misunderstanding. We should work on some &lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../scaling/Pruning/&quot;&gt;pruning&lt;/a&gt; ideas
in order to scale the system without everyone having to invest in storage
space.&lt;/p&gt;

&lt;p&gt;The last of the big components for our hone node is internet connectivity.
To reach our goal we need to be able to download 50 million transactions at
about 300 bytes each in a 24 hours period.&lt;/p&gt;

&lt;p&gt;$$ {50 000 000 * 300 \over {24 * 60 * 60}} = 173611 bytes/sec $$
  $$ {173611 \ over 8} = 22 Kbit/sec $$&lt;/p&gt;

&lt;p&gt;Ideally we go twice as fast to make sure that the node can &#39;catch up&#39; if it
were offline for some time. We may want to add some overhead for other
parts as well. But 22Kb is below the minimum internet speed that can be
acquired practically everywhere as the basic plan. 2Mb (100 times faster)
is practically available in all parts of the world. 2Gb which is 100,000
times faster than what we need to reach our plan in 5 years is available
in countries like Japan today.&lt;/p&gt;

&lt;p&gt;Home nodes have absolutely nothing to fear from even a huge growth of
Bitcoin to about 50 million daily users, their hardware and internet will
cover them with no pains, especially in about 5 years when more software
optimizations may have been created.&lt;/p&gt;

&lt;p&gt;Notice that there is no dependency on things like Moore&#39;s law here, no
hardware growth is needed to reach our goal.&lt;/p&gt;

&lt;h2 id=&quot;atypicaluser&quot;&gt;A typical user&lt;/h2&gt;

&lt;p&gt;A typical user is suggested to use a phone or hardware wallet.  The
actual requirements are really not a lot to be able to make payments safely
and fast if you use
&lt;a href=&quot;http://bitcoinfactswiki.github.io/Scalability/#Simplified_payment_verification&quot;&gt;SPV&lt;/a&gt;
clients.&lt;/p&gt;

&lt;p&gt;Current wallets are in need of some work, though. They are typically quite
greedy in using network to update the state of the wallet. While useful,
this is not wanted in many situations. When I&#39;m abroad on an expensive
data-plan, for instance.&lt;/p&gt;

&lt;p&gt;There is no need to do any communication with the network before creating a
transaction that pays a merchant. Only the actual payment itself needs to
be transferred to the Bitcoin network.&lt;/p&gt;

&lt;p&gt;A typical user uses a phone. On the topic of scaling there is little to
nothing he has to do in order to continue working with on-chain scaling.&lt;/p&gt;

&lt;p&gt;Usability and related topics need substantial amounts of work, though.&lt;/p&gt;

&lt;h2 id=&quot;atypicalminingnode&quot;&gt;A typical mining node&lt;/h2&gt;

&lt;p&gt;Miners need a full node. Where &#39;full&#39; means that it validates all
transactions.  In addition to what a home-node needs, a miner also needs
a fast connection between miners and to have a fast way to broadcast his
blocks to other miners.&lt;/p&gt;

&lt;p&gt;Just like with a typical home-node the amount of bandwidth and harddrive
and CPU speed are already today mostly sufficient for being part of the
network.&lt;/p&gt;

&lt;p&gt;Additionally, the miner uses his node to create block templates. Which
means he takes a section of the pool of unconfirmed transactions and
creates a block based on that. This process has seen some optimizations
already, but more could be made.  For instance the getblocktemplate RPC
call checks the block it just created for validity before it returns it.
This check takes quite a lot of time and a simple solution would be to
decouple the returning of the block and the validation so the miner can
start mining optimistically over the check passing (it should pass in 100%
of the cases anyway).&lt;/p&gt;

&lt;p&gt;The bigger the blocks get, the more data is returned and the system
currently uses JSON which is almost the worst type of data-container for
large binary data-blobs.  A simple replacement of the RPC interface with
something that just changes the communication format to be binary is
relatively easy to do (a month project, probably) and likely needed for
miners to not end up waiting to long on this.&lt;/p&gt;

&lt;p&gt;In our baseline node we explained that it took 7 hours to fully sync a
brand new node from zero.  This will stop being the case when we scale up
to much bigger sizes.  It will start taking a substantial amount of time to
do the initial sync.  Yet, a miner requires a fully synced node.
Bitcoin Classic already has one big change there that will push down the
validation time substantially. It introduced dynamic checkpoints which
allow the node to skip validation of transaction data by assuming that
about a week worth of blocks will not be build on top of double-spend data.
This would remove the validation of 100s of millions of transactions for a
starting node.&lt;/p&gt;

&lt;p&gt;Another suggestion for future Bitcoin clients meant for miners is that a
new node can be pointed to a known and trusted node.  The new node would
then receive the UTXO and all other details it needs to be up and running
quickly from this trusted node.  Which means that after downloading only a
couple of gigabytes you can have your new node up in 10 minutes.&lt;/p&gt;

&lt;p&gt;The most important improvements for mining are various ways to ensure fast
download and upload of the actual new blocks.&lt;/p&gt;

&lt;p&gt;First there is xthin, which is a way to make a 1MB block only cost 25KB to
send to all miners.  This scaling is linear in that a 10MB block will
likely be around 250KB to send.&lt;/p&gt;

&lt;p&gt;Next to that is a technique I called &quot;optimistic mining&quot; which helps miners
by splitting the uploading of blocks into two parts. One is a super fast
notification of the new block. Just the block-header. A miner receiving
such a header validates it has valid proof of work and then can start
mining empty blocks on top.  When the full block has arrived and all
transactions are seen. All transactions in the mempool are updated to
account for the new block, and last, a new block template is created with
as many transactions as fit, only then does the miner start mining it.&lt;/p&gt;

&lt;p&gt;A mining node has no need for either a &lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../On%20Mining%20and%20Wallets&quot;&gt;wallet in their
node&lt;/a&gt; or to have a history of blocks on their
node, so they can turn on &lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../scaling/Pruning/&quot;&gt;pruning&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Many of these techniques are already in development or planned to be
developed in the next year or so.  In order to reach our 50 million users
per day in 5 years most of these will be more than enough to make a miner
able to keep connected to the Bitcoin network without having to invest in a
high-end server for the Bitcoin node.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;The goal I tried to argue from is 50 million users per day. This goal is
a huge increase from today. But to make sure we do it properly, my goal is
set 5 years in the future.&lt;/p&gt;

&lt;p&gt;Scaling Bitcoin-nodes is ultimately boring work with very little effort
needed because it turns out that a modern simple system can already scale
easy 10000 times higher than the current maximum allowed size.&lt;/p&gt;

&lt;p&gt;Scaling the entire system takes a little more work, but mostly because
miners have not received a lot of new features that they would need in
order to make scaling safe for them.  Most of those features could be added
in a matter of months, with technologies like xthin blocks and optimistic
mining already well underway.&lt;/p&gt;

&lt;p&gt;The conclusion that I have to draw is that the goal of 50M/day is not just
reachable, the timeline of 5 years is likely one that we will beat quite
easily.&lt;/p&gt;

&lt;p&gt;Smart tricks like Lightning network are not mentioned at all in this
document because there is no need for them. Bitcoin can scale on-chain
quite easily with almost no risk. Ideas like Lightning are quite high risk
because there are so many unknowns.&lt;/p&gt;

&lt;p&gt;By far the biggest problem with regards to scaling today is the protocol
limit of 1MB block size.  This should be removed as soon as possible.&lt;/p&gt;
</description>


</item>
<item>
	<title>Innovation - OnlineScaling</title>

	<guid isPermaLink="false">http://zander.github.io//posts/Innovation%20-%20OnlineScaling/</guid>

	<link>http://zander.github.io//posts/Innovation%20-%20OnlineScaling/</link>



	<category>Bitcoin</category>

	<category>Community</category>

	<category>Mining</category>


	<pubDate>Mon, 04 Jul 2016 10:06:57 +0000</pubDate>
	<dcterms:modified>2016-07-11T08:02:17Z</dcterms:modified>


	<description>&lt;p&gt;Last weekend we had the On-chain scaling conference which was a big success
with lots of excellent speakers and a large amount of visitors asking
questions and showing interest.&lt;/p&gt;

&lt;p&gt;I understand that a lot of people didn&#39;t manage to see them live for
various reasons. Not the least of them being time-zone differences.&lt;/p&gt;

&lt;p&gt;When my talk went onto YouTube I decided to put up a transcript here.
The actual talk can be found on &lt;a href=&quot;https://youtu.be/TCj84RKdjTs&quot;&gt;youtube&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;transcript&quot;&gt;Transcript&lt;/h2&gt;

&lt;p&gt;About 10 years ago I worked at Trolltech, a small Norwegian company making
tools for developers to build beautiful applications. I worked there for
some years when we got acquired by Nokia.
Nokia wanted our development libraries to work fast and smooth on their
phones as well as on traditional desktops.&lt;/p&gt;

&lt;p&gt;As this was a developer-driven company many developers came up with
solutions on how to reach that goal.  These developers showing off their
ideas meant we had lots of awesome projects to chose from. The projects can
roughly be split into 2 sides.   The &quot;optimization&quot; side which easily
fixes a hundred little speed problems . And a &quot;Big-Changes&quot; side.  These are
projects that require much more time because they change some fundamental
ideas, but they also have a lot larger return on investment.&lt;/p&gt;

&lt;p&gt;I would argue that Bitcoin is in the same position now.  We &lt;em&gt;have&lt;/em&gt; to get
better and we have to scale Bitcoin for many more expected users coming
in over the next years.&lt;/p&gt;

&lt;p&gt;My experience with this process in Trolltech was that all the small,
low-risk changes to make it faster were a huge success. They were needed,
and they made a huge difference.&lt;/p&gt;

&lt;p&gt;On the other hand, the larger &quot;Big-Changes&quot; inevitably introduced more risk and
they forced people using our software to change their behavior to actually
use the new concepts and ideas.
For those reasons their effort ended up taking several years to bear fruit.&lt;/p&gt;

&lt;p&gt;In the end both groups pulled it off, and the results are in
my personal opinion simply unique and amazing.&lt;/p&gt;

&lt;p&gt;Some lessons I learned from those projects at Trolltech are;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;we need researchers to do what they do best. Come up with strange and
exciting ways to do things better.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;we also need people doing the boring, &quot;optimization&quot; work, making
networking protocols work faster and more reliably as a simple example.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This conference presents various &quot;optimization-level&quot; changes that will make
Bitcoin scale much better than it does now. With very little pain, and from
experience I expect quite a big gain.
We call this &lt;em&gt;on-chain&lt;/em&gt; scaling, because whatever your belief is on
which path leads to Bitcoins success, if we want to scale, we need on-chain
transactions to scale beyond the current 3 transactions per second.&lt;/p&gt;

&lt;p&gt;For the next years some changes are being prepared which
by the nature of them being fundamental changes
in the way that Bitcoin will end up being used, will take much longer to create and rollout.  I&#39;ve
seen plans like Segregated Witness and the Lightning Network, interesting
ideas, for sure.  Various teams are working on that and I wish them all the
luck. It is already clear that we can&#39;t expect those scaling solutions to have
any reasonable impact without on-chain scaling solutions being rolled out
as well.&lt;/p&gt;

&lt;p&gt;This makes sense off-course, when you think about it, you need the
foundation to be strong when building on top of it.&lt;/p&gt;

&lt;h2 id=&quot;bitcoininanutshell&quot;&gt;Bitcoin, in a nutshell&lt;/h2&gt;

&lt;p&gt;Now, enough with the high level talk, lets see some actual ideas.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain1.gif&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain1.gif&quot; width=&quot;400&quot; height=&quot;224&quot; class=&quot;img&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is the idea of Bitcoin.
We have a single computer that receives transactions and groups them all in
its memory pool.  What it does at the same time is Bitcoin checks each of
those transactions for validity and after some time those transactions are
combined into a block.&lt;/p&gt;

&lt;p&gt;Every single transaction entering this Bitcoin computer is checked that the
transaction is a legal one.  For instance, a payment from person A to
person B can only be created by person A. We use cryptographic proof to
check that the person initiating the transaction is actually the owner of
the coins he or she he sending.&lt;/p&gt;

&lt;p&gt;Bitcoin also checks that people don&#39;t try to send the digital coins to two
people at the same time.  The Bitcoin application holds all transactions in
storage and if one comes in that tries to spend already spent money, it is
simply rejected.&lt;/p&gt;

&lt;p&gt;When a block comes in it makes the transactions contained in that block
permanent and Bitcoin will merge that block into its database.
The transactions it had in memory are now removed if they were already in
the block, or no longer valid because of other transactions in the block.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain2.gif&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain2.gif&quot; width=&quot;400&quot; height=&quot;224&quot; class=&quot;img&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bitcoin is essentially fully operational with just one node, but it works
with duplication of its functionality over different nodes. Here on screen
are 5 nodes.&lt;/p&gt;

&lt;p&gt;When a transaction comes in, the node validates it and if its valid the node
will forward it to all its neighbors. Which do the same and forward it to
their neighbors.  In less than 1 second 50% of the network will have the
transaction, in less than 4s practically all of them will have it.&lt;/p&gt;

&lt;p&gt;These nodes are in many respects exact duplicates, so technically there is
little reason to have more than one node, except maybe failover.
Politically this duplication means we avoid centralized decision making. We
avoid one operator being able to tell the rest of the world what Bitcoin
will look like today. This is assuming we make the system work fast enough.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain3.gif&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain3.gif&quot; width=&quot;400&quot; height=&quot;224&quot; class=&quot;img&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Blocks, the big collections of transactions, get copied between nodes as
well. The propagation path is similar to transactions.  Currently we send
blocks as a complete chunk of data in one go. This is then validated by a
node to follow the Bitcoin rules and forwarded to its neighbors.&lt;/p&gt;

&lt;p&gt;A healthy network has a large number of Bitcoin nodes to ensure operation
and to allow some of them to be removed without harming Bitcoin as a
whole. Damage to any part of the network will just get routed around.&lt;/p&gt;

&lt;p&gt;Naturally, with a large number of nodes, how they are networked together
becomes more important and that networking layer itself becomes a source of
failure.&lt;/p&gt;

&lt;p&gt;What I&#39;ve skipped over so far is where the blocks come from. A block is
created by a miner.
See, here is one in the bottom left corner.&lt;/p&gt;

&lt;p&gt;It creates a block and sends it over the network.
Each node turning blue means they received the data.&lt;/p&gt;

&lt;p&gt;Now, because a block is actually a substantial amount of
data, it will take longer than the one second that a single transaction
took.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain4.gif&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain4.gif&quot; width=&quot;400&quot; height=&quot;224&quot; class=&quot;img&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bitcoinstats.com reports between 10 seconds and a minute to propagate a 1MB
block to practically the whole network.&lt;/p&gt;

&lt;p&gt;If we start making bigger blocks, this time will go up. More data means slower
propagation times.&lt;/p&gt;

&lt;p&gt;As the mining difficulty is adjusted every 2 weeks to  make sure that the
time between blocks stays on average 10 minutes, the time it takes to send
an entire block is not a big deal for end users. As long as they can
download blocks faster than they get created, things will continue working.
Not optimally, but it works.&lt;/p&gt;

&lt;p&gt;There are many people using Bitcoin that have higher requirements than
that, though, and the
current way that Bitcoin works leaves a lot of space for improvement.&lt;/p&gt;

&lt;h2 id=&quot;howdoesthisworkforminers&quot;&gt;How does this work for miners?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/presentation-onchain5.png&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../posts/Innovation - OnlineScaling/400x325-presentation-onchain5.png&quot; width=&quot;400&quot; height=&quot;325&quot; class=&quot;float-right&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&#39;m currently focussing on miners. How to make sure that miners get the
best out of the system. To explain what I&#39;m working on I will first show
what happens with miners using the Bitcoin software.&lt;/p&gt;

&lt;p&gt;I&#39;m going to draw the time as shown from the perspective of two miners. One
at the top of the screen, and another miner in another physical location at
the bottom of the screen.&lt;/p&gt;

&lt;p&gt;Two miners are mining and one finds a nonce that makes his block valid.
So this miner is happy, he just made several thousands of dollars worth of
money. At least, as long as he can convince the rest of the world to use
this block he just completed to build on top off for following Bitcoin
blocks.  This implies his block is seen by the rest of the network before
any competitors block have finished their block.&lt;/p&gt;

&lt;p&gt;To do so, he sends this block over the network to another miner.
The mean propagation time measured by Peter Rizun for blocks between 900kb
and 1MB shows about 4 seconds, but as soon as you hop over the great
firewall of China this rises to a mean of 17.4 seconds.  I&#39;ll use the
real-time example of 10 seconds here mostly because I don&#39;t talk so fast
anyway.&lt;/p&gt;

&lt;p&gt;Now, after the miner on the bottom received the block, he will be able to
start mining on top of that.&lt;/p&gt;

&lt;p&gt;What you may notice is that the miner on the bottom is essentially doing
work for about 10 seconds that is useless. He was still competing in the
competition for block 1 while that race has already been won by another.
He just didn&#39;t know that yet.&lt;/p&gt;

&lt;p&gt;Lets take a look at my proposal using &quot;Optimistic mining&quot;, which tries to
fix this specific little issue.&lt;/p&gt;

&lt;p&gt;Same situation, one miner finds a block.  Here is a difference. I split up the block into two parts, one is teeny
tiny and send over the network in close to the speed of light and the other
is the actual block, unchanged from before.&lt;/p&gt;

&lt;p&gt;While the entire block is being sent, the miner at the bottom is now all of a
sudden able to mine on top of this new block. Therefore no longer losing money
doing work that is useless.
Because the full block with all the transactions hasn&#39;t arrived yet he
can&#39;t know which transactions were included in it, and thus which
transactions he can safely include in his block. The solution to this is
for his block to be empty.&lt;/p&gt;

&lt;p&gt;The miner switches to mining a full block as soon as he received the whole
block with transactions and is able to decide which transactions to
include in his block.&lt;/p&gt;

&lt;p&gt;The 10 seconds highlighted here is the propagation time of a full block.
This time can be influenced by many things. Bigger blocks can make it take
longer. Network attacks may make it essential to ask the original miner for
more details, slowing down the propagation time. And most importantly, as
we currently see with the great-firewall of china, some countries may just
not have such a great connection to the rest of the world.  I don&#39;t think
its a good idea that a miner in Australia loses money just because he has a
slower connection to the rest of the world.&lt;/p&gt;

&lt;p&gt;Optimistic mining means a miner is made immune to any propagation delays of
the transactions in a block. This only can mean good things to avoid
centralization of mining power.&lt;/p&gt;

&lt;p&gt;In my designs the teeny-tiny part of the block a miner sends out as soon as
he finds a block will be just a block header making it approximately 100 bytes.
A node can validate this with a cheap check and then forward it.&lt;/p&gt;

&lt;p&gt;Two details are important here; the data is forwarded by any node to
its peers and thats it.  There is no more network traffic that a peer
generates based on this.  It is just a way to broadcast a new piece of data
as fast as possible, as far as possible.&lt;/p&gt;

&lt;p&gt;As I promised, these changes are mostly boring and really not
noble price worthy. I still get excited from changes that have a
substantial benefit, though. But I&#39;m just that kind of geek.
These changes do help a lot when you add many of them together and
end up with a massively better scaling system than what we have today.&lt;/p&gt;

&lt;h2 id=&quot;whattoworkonnext&quot;&gt;What to work on next&lt;/h2&gt;

&lt;p&gt;If we look at what it means to scale Bitcoin today we look at all the
obvious resources that any computer program needs. Most of them are really
not an issue. For instance it would take 75 years to fill up a mainstream
harddrive of 3TB with todays block size.  People run the client on a
raspberry Pi. And it copes just fine.&lt;/p&gt;

&lt;p&gt;In Bitcoin the biggest scaling issue we have today is the inefficient use
of bandwidth and the poor peer to peer network.  This is demonstrated best
by the usage of a centralized relay system which operates outside of the
Bitcoin network that miners use to send blocks to each other as fast as possible.
As long as those centralizes systems are needed we will have a permissioned
system where a new player needs permission to enter.  New player that don&#39;t
get permission to use the relay system that all the other miners are on,
will not be able to compete.
We don&#39;t want a system where the relay operators get to decide what miners
can and can not do, under threat of losing their access and subsequently
their business.&lt;/p&gt;

&lt;p&gt;In Bitcoin we currently have what I&#39;d label a first generation p2p network.
Think about a system that students typically set up in class during
computer science as a play thing. Its making all the traditional mistakes.&lt;/p&gt;

&lt;h2 id=&quot;furtherresearch&quot;&gt;Further research&lt;/h2&gt;

&lt;p&gt;The Bitcoin network uses unlabeled binary blobs to send over the wire. This
implies that developers can never fix a message because old clients would
not understand it and likely fail spectacularly.  Tagged formats, the most
well known of which is JSON, solved this many years ago.
What we need is like HTML where an old browser can still read the
newest format without giving errors. It just ignores the parts it doesn&#39;t
know.&lt;/p&gt;

&lt;p&gt;When I worked for a financial company sending out half a million stock-price
quotes every second, I learned a lot about how to do a binary protocol
properly.
I&#39;ve done some extended testing already with a new on-the-wire protocol that
has looks like its saving on bandwidth and speed quite substantially.
But the real benefit is that it can be extended because the fields are
labeled much like JSON or XML do. Its values are also strongly typed and
extensible.  What that means is that the protocol itself includes the
information that says a value is an int, a bool or a string.&lt;/p&gt;

&lt;p&gt;Making such a chance would be very beneficial to make the protocol more
maintainable by allowing bugfixes to be made that are backwards compatible
in a clean manner.&lt;/p&gt;

&lt;p&gt;Another issue we have with our peer to peer system is based on how an
individual node finds other nodes to connect to. We have some code
that decides based on the IP-address numbers whom to connect to.
The logic seems to be
that an IP address is a good indication for location, so it searches to
connect to many different locations.
Unfortunately, this is overstating the correlation between addresses and
distance so this is only slightly better than pure randomly choosing whom to
connect to.&lt;/p&gt;

&lt;p&gt;Why is this important? Lets take an example of 2000 nodes, all around the world that
want to get a message as fast as possible to all of those nodes,
my thinking is that we each node should measure the distance to another
node by seeing how long it takes to send a message and the message to come
back to us.&lt;/p&gt;

&lt;p&gt;We can then order the
sending of the messages so longer distance messages are send first and
shorter distance messages are send later.&lt;/p&gt;

&lt;p&gt;Think about it like this, you could send a message by courier to the next
village and he sends it to the next and so on.
Or you send a courier by plane to the next big city and he starts sending
couriers out from there.
The idea is that a message would get to the the other side of the globe in
5 hops instead of 50.&lt;/p&gt;

&lt;p&gt;To be fair, there are really not a lot of systems out there that create a
peer to peer system of this scale that have no central server and have to
send messages through the entire system as fast as possible. But this lack of
competition just means its going to be a nice challenge to find what works
and what doesn&#39;t.&lt;/p&gt;

&lt;h2 id=&quot;someotherdetails&quot;&gt;Some other details&lt;/h2&gt;

&lt;p&gt;We have some work done that fixes the problem that while downloading and
validating a block that node can&#39;t relay transactions.&lt;/p&gt;

&lt;p&gt;For our protocol to get to a more professional level we&#39;d also need message
priority. A node pushing something to the top of the message-queue to be sent.&lt;/p&gt;

&lt;p&gt;We&#39;d likely want to support both TCP and UDP queues where UDP is used for
higher-priority but smaller messages.  That would be ideal for the
optimistic mining teeny-tiny block message we want to go around the world in
near lightspeed.&lt;/p&gt;

&lt;p&gt;And last we&#39;d &lt;em&gt;really&lt;/em&gt; need to set a maximum size for a single message. The
telco&#39;s switched to packet switching in the 90s, we&#39;re long overdue.
We now send a single message of one or many megabytes, experience shows that
splitting that up into multiple messages or maybe 50kb, and re-assembling it on the other
side will have a very positive effect on throughput because you can
send bigger data to two peers at the same time, using only twice the wall-time in optimal situations.
But when you are sending a large block to a peer
that is very slow in receiving it, this message chunk-ING will stop slowing
down your sending speed to another peer at the same time.&lt;/p&gt;

&lt;p&gt;I&#39;ve implemented this in another system where the overhead per 50KB message ended
up being only 14 bytes. So I really don&#39;t see any reason to not do this.&lt;/p&gt;

&lt;p&gt;These are useful changes that I&#39;m hoping to see being worked on, if not by
me, then someone else.&lt;/p&gt;

&lt;p&gt;Other issues we will bump into as we get bigger blocks and higher
throughput are going to be found, and fixed as we move forward. I have no
doubt about that. That is the nature of this game, there is always some
optimization that we haven&#39;t done yet.&lt;/p&gt;

&lt;p&gt;Beyond the network layer are a lot of other things that show up as being
useful to work on in order to allow more data to go through Bitcoin cheaper
and faster. Its still young software and I don&#39;t think its been bothered
with profilers or other speed measurements very often. Gavin started a
benchmark suite that never really saw uptake by any of the other
developers. So please expect a huge amount of benefits to happen in the
next years alone for throughput as its easy pickings for optimizations when
its not been done for years.&lt;/p&gt;

&lt;p&gt;I would say that within a year the network would be safely able to handle
between 20 and 50 MB blocks.&lt;/p&gt;

&lt;p&gt;Creating a Bitcoin that, on-chain, can grow and support more users will be
the thing that actually creates more value for the Bitcoin ecosystem.
So while our opponents are discussing how to distribute the money of the
rich differently, until they inevitably run out of money, we are working to
actually create new value to increase your wealth as well as ours.&lt;/p&gt;

&lt;p&gt;Bitcoin has a bright future.&lt;/p&gt;
</description>


</item>
<item>
	<title>ClassicQuality</title>

	<guid isPermaLink="false">http://zander.github.io//posts/ClassicQuality/</guid>

	<link>http://zander.github.io//posts/ClassicQuality/</link>



	<category>Bitcoin</category>


	<pubDate>Thu, 30 Jun 2016 10:33:56 +0000</pubDate>
	<dcterms:modified>2016-07-11T08:02:17Z</dcterms:modified>


	<description>&lt;p&gt;When I first started working with Bitcoin, a couple of years ago, I tried
to find out how to contribute code and to understand the Quality Assurance
policies they held.&lt;/p&gt;

&lt;p&gt;At this time I naturally was talking to people from the Bitcoin Core group,
and the answers I got were quite confusing to me.&lt;/p&gt;

&lt;p&gt;After having worked in the software industry for 20 years I had become very
reliant on good quality assurance policies. As well as good usage of
distributed source management control. Turns out that Core didn&#39;t really
have any of that in place.&lt;/p&gt;

&lt;p&gt;When I was asked to work with Gavin on Bitcoin Classic I first started to
work on quality assurance policies and practices.  And I&#39;m happy to say that
we have reached at least industry standard, if not a little above. But I
haste to say that there is still room for improvement.&lt;/p&gt;

&lt;h2 id=&quot;gitworkflow&quot;&gt;Git workflow&lt;/h2&gt;

&lt;p&gt;The first thing that I changed is that we now have a proper git workflow.
This means that developers fix bugs on the stable branch and we use git
merges to make those bugfixes go up to the development branch.
You will find this process in any git book, so I wont&#39; spent too much time
on this.  The important part is that merges between branches is done often
and that way we can&#39;t lose work or introduce bugs by doing it manually.
See also our &lt;a href=&quot;https://github.com/bitcoinclassic/bitcoinclassic/blob/develop/CONTRIBUTING.md&quot;&gt;contributing
document&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;releaseprocess&quot;&gt;Release process&lt;/h2&gt;

&lt;p&gt;The second part that changed is the release process itself.
Based on the fact that we now have a stable branch that is always
releasable the release process will become easier.  The aim is to follow
the good old open source concept of &quot;Release early, release often&quot;.&lt;/p&gt;

&lt;p&gt;One of the biggest changes is that we now follow the &lt;a href=&quot;http://semver.org/&quot;&gt;Semantic
Versioning&lt;/a&gt; concept which is almost universal for open
source software as well as for many closed source products.&lt;/p&gt;

&lt;p&gt;Let me quote the core concept;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Given a version number MAJOR.MINOR.PATCH, increment the:&lt;/p&gt;
  
  &lt;ol&gt;
  &lt;li&gt;MAJOR version when you make incompatible API changes,&lt;/li&gt;
  &lt;li&gt;MINOR version when you add functionality in a backwards-compatible
  manner, and&lt;/li&gt;
  &lt;li&gt;PATCH version when you make backwards-compatible bug fixes.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Additionally I wrote this in the release tag of v1.1.0&lt;/p&gt;

&lt;p&gt;At first we wanted to follow the Core releases, but they have different
core-values and push out hundreds of lines of new code in a bugfix release
which feels dirty to have to inherit.  The result of that is that the CSV
soft fork code feature release has received a bigger version bump.  And
when that disconnect between Core and Classic versions it also stopped
making sense to stay close to versioning of Core. &lt;br /&gt;
It was time to review the numbering scheme altogether.&lt;/p&gt;

&lt;p&gt;When I talked about the &quot;less than 1.0&quot; versioning over beers with
&lt;a href=&quot;https://en.wikipedia.org/wiki/Eric%5FS%2E%5FRaymond&quot;&gt;Eric S. Raymond&lt;/a&gt; (author of &lt;a href=&quot;https://en.wikipedia.org/wiki/The%5FCathedral%5Fand%5Fthe%5FBazaar&quot;&gt;The Cathedral and the Bazaar&lt;/a&gt;) he explained it like this: &lt;br /&gt;
The idea was that when the app reaches the set of features required
for the user with the lowest demands to use it for its intended usage,
that&#39;s when you call it 1.0.&lt;/p&gt;

&lt;p&gt;Bottom line, Bitcoin is certainly far past its 1.0 release. We will follow
the Semantic Versioning from now on.&lt;/p&gt;

&lt;h2 id=&quot;continuesintegrationbuilding&quot;&gt;Continues Integration building&lt;/h2&gt;

&lt;p&gt;What I was really missing was a proper &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuous%5Fintegration&quot;&gt;Continuous integration&lt;/a&gt; (CI) system. Naturally, there is the freely
available Travis.  But thats been a frustrating experience and really not
useful as a build server. Apart from the fact that Travis is really slow
(taking an hour or more), some and 60% of the time when it says there is a
failure, it actually isn&#39;t a problem in our code, its really not useful to
rely on.&lt;/p&gt;

&lt;p&gt;I got a dedicated server in a secure environment and installed Teamcity on
it. Teamcity is one of the most used CI software systems out there and
quite useful for our purposes.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/teamcity.png&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../posts/ClassicQuality/500x500-teamcity.png&quot; width=&quot;500&quot; height=&quot;463&quot; class=&quot;float-right&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It does a couple of things;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;every single time a change is made in Git (in all branches) it builds
this for all platforms and runs unit tests at least for the Linux ones.
Notice that it does the building in a fraction of the time that Travis
took. Typically a build completes in less than 15 min.&lt;/li&gt;
&lt;li&gt;It builds both using the &#39;gitian&#39; concept of reproducible (or static)
build environment for all platforms as well as using the native Linux way
of using the platform dynamic-libraries (dlls). This makes sure we know it
works on more than one version of boost and all the other supporting
libraries.&lt;/li&gt;
&lt;li&gt;It builds nightly builds of the development branch allowing people to
test these that don&#39;t want to compile.&lt;/li&gt;
&lt;li&gt;It pushes the build to remote builders (like Ubuntu&#39;s launchpad) to have
an easy way to distribute nightly builds or maybe even future releases with
minimum effort.&lt;/li&gt;
&lt;li&gt;It tests the Debian contrib to actually build properly.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As I mentioned, the server is in a secure location. What that means is that
it is not connected to the internet and physically protected to make sure
we can trust the output of that server.  When we ship sources anyone can
check quickly if they are unaltered from the tags in git. But with binaries
(evil) changes can be much harder to detect.  So I refuse to gpg-sign any
releases unless I know they actually came from the exact sources that are
in git, visible for all.&lt;/p&gt;

&lt;h2 id=&quot;ongoingwork&quot;&gt;Ongoing work&lt;/h2&gt;

&lt;p&gt;There is plenty of issues that could use improvements.  It turns out that
the original developers don&#39;t really like writing unit tests and the code
lacks any organization to make unit testing practical or easy.  With some
small changes such efforts could be made much easier.&lt;/p&gt;

&lt;p&gt;We also have exactly one executable that runs all the test. Which is
against the unit testing practices of having small units because one
failure in one test can cause a lot of tests afterwards to start failing
too, mostly because the memory states were not cleaned up properly after a
failure.&lt;/p&gt;

&lt;p&gt;Ideally we have a lot of small test executables which can be run by a
simple runner. With the added benefit that you can run various in parallel
(one per cpu-core) which makes the whole complete much faster as well.&lt;/p&gt;

&lt;p&gt;We currently have a benchmark framework, but nothing in there. The idea of
a benchmark is that code which is time critical can be tested in there and
the output can be printed and plotted over a long time (months) to see that
such time critical code doesn&#39;t get slower by unintended changes from
release to release. &lt;br /&gt;
I find it hard to believe that Bitcoin has no time critical code, as such
we should be able to find value to locate, test and keep code from getting
slower.&lt;/p&gt;

&lt;p&gt;Better integration Linux distro&#39;s. Bitcoin was made to be shipped as a big
executable with all the libraries inside. The thinking was that this saves
the application from misbehaving when another library changes behavior.
While the idea seems logical, it shows a lack of experience because the
open source community has been solving this problem for 30 years and it
does so quite successfully.  Going against that only introduces a different
set of problems.  For instance when the libc DNS exploit was made public
Bitcoin dodged a bullet because libc is one of the very few libraries we
don&#39;t actually compile in. But imagine any of the libraries we include has
such a similar vulnerability and the only way to solve that is to re-build
Bitcoin and get everyone to manually update.   The Linux alternative of
just running an &lt;code&gt;apt-get upgrade&lt;/code&gt; or similar is vastly more secure and
better supported.&lt;/p&gt;

&lt;p&gt;As mentioned in the CI section, I already added support for Classic in
launchpad. This may be something to expand upon and support more Linux
distros in a similar fashion.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Bitcoin Classic has a strong Quality Assurance policy, adopts long time
industry standard practices and sheds unsafe self-invented ones from
upstream.&lt;/p&gt;

&lt;p&gt;We also take all the best practices from Open Source and Free Software to
make releases often for those that want to test the latest and contribute
by reporting issues, or simply by being part of the network.&lt;/p&gt;

&lt;p&gt;The future is bright!&lt;/p&gt;
</description>


</item>
<item>
	<title>On Mining and Wallets</title>

	<guid isPermaLink="false">http://zander.github.io//posts/On%20Mining%20and%20Wallets/</guid>

	<link>http://zander.github.io//posts/On%20Mining%20and%20Wallets/</link>



	<category>Bitcoin</category>

	<category>Mining</category>


	<pubDate>Mon, 27 Jun 2016 11:31:01 +0000</pubDate>
	<dcterms:modified>2016-07-11T08:02:17Z</dcterms:modified>


	<description>&lt;h3 id=&quot;dontleaveyourmoneyonthestreet.&quot;&gt;Don&#39;t leave your money on the street.&lt;/h3&gt;

&lt;p&gt;Bitcoind is labelled as the backend of the network. When I explain this to
friends I explain it like its the router that you have stuffed behind the
sofa or if you are more professional, in a server room, sometimes not even
in the same country you are in.
Either way, it is something needed for everything else to work. But mostly
ignored.&lt;/p&gt;

&lt;p&gt;This is how I imagine the users of Bitcoin Classic to use the software, and
it is the way I think it should be. They use it as something that just
works to make it possible for them to keep their business or infrastructure
running.&lt;/p&gt;

&lt;p&gt;One such group of Bitcoin Classic users are the miners, they run
bitcoin-classic to have an accurate view of the state of the network.  The
new transactions are collected in Bitcoin Classic and it creates new block
templates for them. In short; Bitcoin Classic helps miners connect to the
network.&lt;/p&gt;

&lt;p&gt;What is totally out-of-character with the design that Bitcoin has had for
years is that, when the miner actually mines the block that the
block-reward is &quot;stored&quot; in the Bitcoin node.&lt;/p&gt;

&lt;p&gt;This means that your Bitcoin Classic suddenly isn&#39;t just a piece of network
infrastructure anymore.  It holds thousands of dollars worth of value. And
because of that you&#39;d have to protect it.  Which is not always compatible
with the way that you want to use a piece of network infrastructure.&lt;/p&gt;

&lt;p&gt;See, the original Bitcoin node that Satoshi made was a reference client and
it included the ability to relay messages, it has a wallet and it knows how
to mine blocks.&lt;/p&gt;

&lt;p&gt;Over the years we stopped using the mining software because other software
and hardware solutions have appeared that were much better.&lt;/p&gt;

&lt;p&gt;We have also seen many better wallets which are much more used than a full
node based wallet.&lt;/p&gt;

&lt;p&gt;All of those still use the bitcoin full node software, like Bitcoin
Classic, as a platform to build on.  They communicate via various channels
with the Bitcoin software which in turn connects them to the Bitcoin
Network.&lt;/p&gt;

&lt;p&gt;It is in my opinion time to separate Bitcoin Mining from the Bitcoin
Wallet. We should no longer force Miners to use the Bitcoin wallet that is
shipped in Bitcoin Classic. We should no longer force the horrible security
practice of storing bitcoin private keys (and the money they represent) on
a piece of equipment that really is meant to be like a router or a hub
connecting your business to the Bitcoin network.&lt;/p&gt;

&lt;h3 id=&quot;stopdemandingawalletinaminingnode&quot;&gt;Stop demanding a wallet in a mining node&lt;/h3&gt;

&lt;p&gt;In Bitcoin Classic&#39;s development branch we have changed the
system to allow mining on a node that does not have a wallet compiled in.&lt;/p&gt;

&lt;p&gt;I introduced a new RPC command called &lt;code&gt;createaddress&lt;/code&gt;, which returns
something like this;&lt;/p&gt;

&lt;pre&gt;
{
  &quot;address&quot;: &quot;1E852VpivAYpZcwGo5bNB9U4twjnJfrL2c&quot;,
  &quot;pubkey&quot;:
&quot;0303a60a215af3ea3240705db3201b5161445e1bdbd1e4e942284cfd9e9ede0ea1&quot;,
  &quot;private&quot;: &quot;KyjwYTJrhAS14fV7fP16Z9bhiudpPcSTT5HpPgpoampS57zgT59w&quot;
}
&lt;/pre&gt;

&lt;p&gt;The private key is the one piece of information needed to later spent the
money that would be stored on the address. To benefit from this change the
miner would store this private key in a secure location.&lt;/p&gt;

&lt;p&gt;The pubkey and the address are not needed to be stored securely, they
can be used in future mined blocks.  When a block is mined with the pubkey
set, the money can later be redeemed using the safely stored private key.&lt;/p&gt;

&lt;p&gt;A second new RPC command is &lt;code&gt;setcoinbase&lt;/code&gt;.  When called with the &#39;pubkey&#39;
field from above this will cause any following calls to
&lt;code&gt;getblocktemplate&lt;/code&gt; to be generated so when it is mined all the fees and
block reward will go to the address.&lt;/p&gt;

&lt;p&gt;People can use the output of &lt;code&gt;createaddress&lt;/code&gt;, &lt;strong&gt;or if they don&#39;t like
change, just use the existing &lt;code&gt;getnewaddress&lt;/code&gt; and &lt;code&gt;validateaddress&lt;/code&gt; rpc
calls to create a coinbase that will end up in your bitcoind wallet&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Additionally the command-line option &lt;code&gt;--gencoinbase&lt;/code&gt; is added to bitcoind
which has the same effect as the setcoinbase RPC command and that may be
useful to use until the mining software is upgraded to use these new RPC
commands. Because calling getblocktemplate without setting the coinbase
will now cause an error to be returned.&lt;/p&gt;

&lt;p&gt;This change is still only available on the development branch, and has not
been scheduled for release just yet.  So &lt;strong&gt;there is still time to give
feedback on what you like or dislike or would like to change&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In my opinion these changes will have the positive effect that miners can
now feel much more safe when their bitcoind connects them to the bitcoin
network, without needing all the security that a full wallet should have.&lt;/p&gt;
</description>


</item>
<item>
	<title>With Information Comes Understanding</title>

	<guid isPermaLink="false">http://zander.github.io//posts/With%20Information%20Comes%20Understanding/</guid>

	<link>http://zander.github.io//posts/With%20Information%20Comes%20Understanding/</link>



	<category>Bitcoin</category>

	<category>Community</category>


	<pubDate>Tue, 24 May 2016 18:35:02 +0000</pubDate>
	<dcterms:modified>2016-07-11T08:02:17Z</dcterms:modified>


	<description>&lt;p&gt;The story I want to tell today is one of confusion.&lt;/p&gt;

&lt;div class=&quot;float-right&quot;&gt;
&lt;a href=&quot;http://zander.github.io//tags/Bitcoin/../../images/escapeTrap.jpg&quot;&gt;&lt;img src=&quot;http://zander.github.io//tags/Bitcoin/../../posts/With Information Comes Understanding/400x300-escapeTrap.jpg&quot; width=&quot;400&quot; height=&quot;300&quot; class=&quot;img&quot; /&gt;&lt;/a&gt;

&lt;/br&gt;&lt;i&gt;Confusing translation. By &lt;a href=&quot;https://www.flickr.com/photos/dandownunder/220926841/&quot;&gt;dandownunder&lt;/a&gt;&lt;/i&gt;
&lt;/div&gt;

&lt;p&gt;I have been a software developer for various decades and in that time the
way that I start a new job or a new task is similar.  It is one of
learning. When I started in a company that creates medical hardware I ended
up spending quite some time reading through books meant for nurses. When I
started in a company that makes a stock-trading platform I had to learn
about the financial industry.  The knowledge of being a software developer
is similar to knowing English or Russian as a novel writer.  It doesn&#39;t
mean you have anything interesting to write.  You need to learn.&lt;/p&gt;

&lt;p&gt;This is why I love my profession of software developer. I get to do
something completely different on a regular basis.&lt;/p&gt;

&lt;p&gt;Learning about Bitcoin was surprising difficult. I&#39;ve been learning for
almost 4 years and I am certain I will continue for many more. &lt;br /&gt;
I would have to say that from all the industries that I studied, learning
about Bitcoin details has been the hardest.&lt;/p&gt;

&lt;p&gt;I have been talking to quite a lot of people over these years, from forums
like reddit and 8btc to chat, email and VOIP talking to the experts.  I
found that I was not alone with my difficulty of discovering pertinent
details about Bitcoin.&lt;/p&gt;

&lt;p&gt;The following scenario would happen on a regular basis: A couple of random
people on the internet are in a discussion about some detail. For instance
they talk about the claim that miners would never willingly break the
Bitcoin consensus rules. &lt;br /&gt;
After some time an expert comes in and resolves the conflict by stating
some fact.  In our example, he could say that after the 2012 halving there
were various miners for some hours that continued to mine blocks with 50BTC
reward.&lt;/p&gt;

&lt;p&gt;I&#39;ve always wanted to be so wise and learned that I knew all those facts in
the hope that I could become an expert.&lt;/p&gt;

&lt;p&gt;Until now.&lt;/p&gt;

&lt;p&gt;In Bitcoin there are currently a very small number of experts. This
generates a handful of problems. The most obvious problem is the one I
outlined above, it makes it hard for new people to enter Bitcoin and become
productive. New people need known experts to help them. Many other problems
are more subtle.&lt;/p&gt;

&lt;p&gt;Problems we face today:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;With the experts having more information than the rest of us,
those experts become authority figures. We need their Ok because we will
likely do things wrong otherwise.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bitcoin is a field that spans Economy, Finance, the history of Money,
Psychology, various fields in software architecture (databases,
peer-2-peer networking, cryptography) and probably more. It is impossible
for any one person to be an expert in all of those.  Yet, when we talk to
our Bitcoin experts I never once heard any of them say that they would
rather defer to someone more knowledgeable than themselves.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Discussions about Bitcoin can be about opinions or about well researched
facts.  In the current world it is impossible to differentiate fact from
opinion because we can&#39;t independently validate those facts.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;I have become convinced that the first big step we need to make to create
a more healthy Bitcoin ecosystem is to make access to currently well hidden
facts completely open for anyone to access and contribute to.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Wikimedia &lt;a href=&quot;https://wikimediafoundation.org/wiki/Vision&quot;&gt;writes&lt;/a&gt;;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Imagine a world in which every single human being can freely share in the
  sum of all knowledge.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think that goal is inspiration that Bitcoin could use very well.  I would
like to see a Free Wikipedia for Bitcoin technology.&lt;/p&gt;

&lt;p&gt;There are quite a number websites today that have a small amount of
information, typically on one topic for one specific group of users. For
instance people new to Bitcoin. But nothing that combines those ideas and
facts.&lt;/p&gt;

&lt;p&gt;A special mention should go to the bitcoin.it website which has a lot of
in-depth information.  Unfortunately most of it is hopelessly outdated and
looking through the discussions it becomes obvious this is because it has
been strictly guarded by a small number of people that would remove without
discussion any opinions not already known to them. This kind of behavior
is the death to cooperation.&lt;/p&gt;

&lt;p&gt;The secondary goal, then, should be to create documentation that can not
be censored or controlled.&lt;/p&gt;

&lt;h3 id=&quot;bitcoinwiki.git&quot;&gt;BitcoinWiki.git&lt;/h3&gt;

&lt;h4 id=&quot;partofthesolutiongit.&quot;&gt;Part of the solution; git.&lt;/h4&gt;

&lt;p&gt;Git is a tool used for many years by enthusiasts and professionals alike to
create a distributed
&lt;a href=&quot;http://nvie.com/posts/a-successful-git-branching-model/&quot;&gt;workflow&lt;/a&gt;.
Anyone can create changes and offer them to the world to accept or reject
based on merit only.  Git allows anyone to start contributing without
permission. It also removes the central ownership. No longer is it needed
to convince one group of the worth of your changes, there may be various
groups each creating what they think is the best version.&lt;/p&gt;

&lt;h4 id=&quot;loweringthethresholdofentry.&quot;&gt;Lowering the threshold of entry.&lt;/h4&gt;

&lt;p&gt;While git allows the actual required working together, it is just a basic
layer. Many end users don&#39;t want to use git, and that should be perfectly
Ok. &lt;br /&gt;
Much like Wikipedia allows a user to do everything from a web browser, we
need a way to do the same in order to not scare off people that could
really contribute but don&#39;t have the technical knowledge to install and use
tools on their machine.&lt;/p&gt;

&lt;p&gt;In my search for a solution I found a tool called
&lt;a href=&quot;http://ikiwiki.info/&quot;&gt;ikiwiki&lt;/a&gt;. This is a tool that combines the concept
of a wiki and the concept of distributing control using git.
What one person changes on the website can be merged with what another
person makes at another time. Even when those people use a different
website or a different team to do the work in.&lt;/p&gt;

&lt;h3 id=&quot;startingtherevolution.&quot;&gt;Starting the revolution.&lt;/h3&gt;

&lt;p&gt;To start somewhere I present a website that has all the content (including
all revisions back until its start in 2010) copied from what has so far
been the main Bitcoin wiki. I put them online for now at
&lt;a href=&quot;http://bitcoinfactswiki.github.io&quot;&gt;bitcoinwiki.github.io&lt;/a&gt;. This is a simple
website and editing is currently disabled.
The wiki database is converted to be
&lt;a href=&quot;https://en.wikipedia.org/wiki/Markdown&quot;&gt;markdown&lt;/a&gt;, which is a more modern
alternative than the old wiki used. This is also the native format that
ikiwiki uses. Don&#39;t worry, you likely are not going to have problems with
it as you may already know it quite well. Markdown is used at many places
like
&lt;a href=&quot;https://help.github.com/articles/getting-started-with-writing-and-formatting-on-github/&quot;&gt;github&lt;/a&gt;
and Reddit.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://BitcoinFactsWiki.github.io&quot;&gt;bitcoinwiki.github.io&lt;/a&gt; is the current
version, the complete history is found in git on github
&lt;a href=&quot;https://github.com/BitcoinFactsWiki/english&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But even with the full historical content, I do believe we need some heros
to step up and do some major work. Many pages are hopelessly outdated and
there are quite a lot of flaws in the actual content.&lt;/p&gt;

&lt;p&gt;Next to that, many pages use rendering-templates that have not been ported
over to the git repository. I would suspect that most of them are in fact
irrelevant. Some closer inspection is needed.&lt;/p&gt;

&lt;h4 id=&quot;bepartofthesolutionpleasehelp&quot;&gt;Be part of the solution, please help&lt;/h4&gt;

&lt;p&gt;In my own humble opinion the goal of the old wiki is wrong, it highlighted
all companies in the space which included all gambling sites and places
selling hardware. This is fast-changing information and frankly serves
nobody but the companies.  Likewise, pages about people feel out of place.
It so quickly becomes about being better than anyone else. I don&#39;t have a
wikipedia page and I think I&#39;m better off without it.&lt;/p&gt;

&lt;p&gt;Actual technical information, backgrounds, overviews and historical facts
would be useful to write down. In my opinion it should be a source of
information where fresh content is shared and research published.&lt;/p&gt;

&lt;p&gt;We need people to go in and slice up the bad stuff, move pages to better
locations and move out useless content. I have already spent too much time,
time I could spend on writing better Bitcoin code. So I hope others can
pick up the baton and fork my the bitcoinwiki project on github and work on
making it ready for more and more people to come in add their work and
content.&lt;/p&gt;

&lt;p&gt;Following the title of this blogposts, sharing how Bitcoin works and
sharing knowledge about many of its darker corners will allow the
conversation to shift back into a less emotional one.  It is always easier
to discuss topics when opinions are not confused with facts and facts are
not fought with opinions.&lt;/p&gt;
</description>


</item>

</channel>
</rss>
